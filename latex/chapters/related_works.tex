% !TeX spellcheck = en_US

\section{Threat Analysis And Counter Measurement}
	
	% TODO
	The extension architectures of Chrome extensions and Firefox add-ons were the target of several scientific researches and analysis \cite{Barth10protectingbrowsers,Carlini:2012:EGC:2362793.2362800,Hallaraker:2005:DMJ:1078029.1078861,Liu12chromeextensions:,TerLouw:2007:EWB:1420581.1420583,cs2015sentinel}. To counter found security flaws, the researcher proposed different approaches that range from proposals to remove certain functions to complete new extension models. 
	
	Barth et al. analyzed Firefox's Add-on model and found several exploits which may be used by attackers to gain access to the user's computer \cite{Barth10protectingbrowsers}. In their work, they focus on unintentional exploits in extensions which occur because extension developer are often hobby developers and not security experts. Firefox runs its extensions with the user's full privileges including to read and write local files and launch new processes. This gives an attacker who has compromised an extension the possibility to install further malware on the user's computer. Barth et al. proposed a new model for extensions to decrease the attack surface in the case that an extension is compromised. For that purpose, they  proposed a privilege separation and divided their model in three separated processes. \textit{Content scripts} have full access to the web pages DOM, but no further access to browser intern functions because they are exposed to potentially attacks from web pages. The browser API is only available to the extension's \textit{background} which runs in another process as the content scripts. Both can exchange messages over a string-based channel. The core has no direct access to the user's machine. It can exchange messages with optionally \textit{native binaries} which have full access to the host. \\
	To further limit the attack surface of extensions, they provided an additional separation between content scripts and the underlying web page called \textit{isolated world}. The web page and each content script runs in its own process and has its own JavaScript object that mirrors the DOM. If a script changes a DOM property, all objects are updated accordingly. On the other hand, if a non-standard DOM property is changed, it is not reflected onto the other objects. This implementation makes it more difficult to compromise a content script by changing the behavior of one of its functions. \\
	For the case, that an attacker was able to compromise the extension's core and gains access to the browser's API, Barth et al. proposed a permission system with the principle of least privileges to reduce the amount of available API functions at runtime. Each extension has by default no access to functions which are provided by the browser. It has to explicit declare corresponding permissions to these functions on installation. Therefore, the attacker can only use API functions which the developer has declared for his extension. \\
	Google adapted the extension model from Barth et al. for their Chrome browser in 2009. Therefore, it is also the basis for the extension model which we analyzed in this paper.
	
	Nicholas Carlini et al. evaluated the three security principles of Chrome's extension architecture: \textit{isolated world}, \textit{privilege separation} and \textit{permissions} \cite{Carlini:2012:EGC:2362793.2362800}. They reviewed 100 extensions and found 40 containing vulnerabilities of which 31 could have been avoided if the developer would have followed simple security best practices such as using HTTPS instead of HTTP and the DOM function innerText that does not allow inline scripts to execute instead of innerHtml. Evaluating the isolated world mechanism, they found only three extensions with vulnerabilities in content scripts; two due to the use of eval. Isolated world effectively shields content scripts from malicious web pages, if the developer does not implement explicit cross site scripting attack vectors. Privilege separation should protect the extension's background from compromised content scripts but is rarely needed because content scripts are already effectively protected. They discovered that network attacks are a bigger thread to the extension's background than attacks from a web page. An attacker can compromise an extension by modifying a remote loaded script that was fetched over an HTTP request. The permission system acts as security mechanism in the case that the extension's background is compromised. Their review showed that developers of vulnerable extensions still used permissions in a way that reduced the scope of their vulnerability. To increase the security of Chrome extensions, Carlini et al. proposed to ban the loading of remote scripts over HTTP and inline scripts inside the extension's background. They did not propose to ban the use of eval in light of the facts that eval itself was mostly not the reason for a vulnerability and banning it would break several extensions. 
	
	Mike Ter Louw et al. evaluated Firefox's Add-on model with the main goal to ensure the integrity of an extension's code \cite{TerLouw:2007:EWB:1420581.1420583}. They implemented an extension to show that it is possible to manipulate the browser beyond the features that Firefox provides to its extensions. They used this to hide their extension completely by removing it from the list of installed extensions and injecting it into an presumably benign extension. Furthermore, their extension collects any user input and data and sends it to an remote server. The integrity of an extension's code can be harmed because Firefox signs the integrity on the extension's installation but does not validate it when loading the extension. Therefore, an malicious extension can undetected integrate code into an installed extension. To remove this vulnerability Louw et al. proposed user signed extensions. On installation the user has to explicit allow the extension which is then signed with a hash certificate. The extension's integrity will be tested against the certificate when it is loaded. To protect the extension's integrity at runtime they added policies on a per extension base such as to disable the access to Firefox's native technologies. 
	
	An approach similar to the policies introduced by Louw et al. was developed by Kaan Onarlioglu et al. \cite{cs2015sentinel}. They developed a policy enforcer for Firefox Add-ons called \textit{Sentinel}. Their approach adds a runtime monitoring to Firefox Add-ons for accessing the browser's native functionality and acts accordingly to a local policy database. Additional policies can be added by the user which enables a fine grained tuning and to adapt to personal needs. The disadvantage is that the user needs to have knowledge about extension development to use this feature. They implemented the monitoring by modifying the JavaScript modules in the Add-on SDK that interact with the native technologies.  
	
	In our work, we contribute an analysis of Chrome's extension architecture with the focus on what attacks we can execute with a malicious extension. Therefore, we analyze the permission model of Chrome extensions and show how we can misuse the corresponding API modules. We also give an overview over Chrome's extension, and Firefox's add-on architecture and list commonalities and differences.



\section{Analysis Of Possible Extension Attacks}
	
	Lei Liu et al. evaluated the security of Chrome's extension architecture against intentional malicious extensions \cite{Liu12chromeextensions:}. They developed a malicious extension which can execute password sniffing, email spamming, DDoS, and phishing attacks to demonstrate potential security risks. Their extension works with minimal permissions such as access to the tab system and access to all web pages with \texttt{http://*/*} and \texttt{https://*/*}. To demonstrate that those permissions are used in real world extensions, they analyzed popular extensions and revealed that 19 out of 30 evaluated extensions did indeed use the \texttt{http://*/*} and \texttt{https://*/*} permissions. Furthermore, they analyzed thread models which exists due to default permissions such as full access to the DOM and the possibility to unrestrictedly communicate with the origin of the associated web page. These capabilities allow malicious extension to execute cross-site request forgery attacks and to transfer unwanted information to any host. To increase the privacy of a user, Liu et al. proposed a more fine grained permission architecture. They included the access to DOM elements in the permission system in combination with a rating system to determine elements which probably contain sensitive information such as password fields or can be used to execute web requests such as iframes or images. \\
	
	A further research about malicious Chrome extensions demonstrates a large list of possible attacks to harm the user's privacy \cite{extensions:cns14}. Lujo Bauer et al. implemented several attacks such as stealing sensitive information, executing forged web request, and tracking the user. All their attacks work with minimal permissions and often use the \texttt{http://*/*} and \texttt{https://*/*} permissions. They also exposed that an extension may hide it's malicious intend by not requiring suspicious permissions. To still execute attacks, the extension may communicate with another extension which has needed permissions. \\
	
	
	
\section{Extension Evaluation} 
	
	\textit{Hulk} is an dynamic analysis and classification tool for chrome extensions \cite{184485}. It categorizes analyzed extensions based on discoveries of actions that may or do harm the user. An extension is labeled \textit{malicious} if behavior was found that is harmful to the user. If potential risks are present or the user is exposed to new risks, but there is no certainty that these represent malicious actions, the extension is labeled \textit{suspicious}. This occurs for example if the extension loads remote scripts where the content can change without any relevant changes in the extension. The script needs to be analyzed every time it is loaded to verify that it is not malicious. This task can not be accomplished by an analysis tool. Lastly an extension without any trace of suspicious behavior is labeled as \textit{benign}. Alexandros Kapravelos et al. used Hulk in their research to analyze a total of 48,322 extensions where they labeled 130 (0.2\%) as malicious and 4,712 (9.7\%) as suspicious. \\
	Static preparations are performed before the dynamic analysis takes action. URLs are collected that may trigger the extension's behavior. As sources serve the extension's code base, especially the manifest file with its host permissions and URL pattern for content scripts, and popular sites such as Facebook or Twitter. This task has its limitation. Hulk has no account creation on the fly and can therefore not access account restricted web pages. \\
	The dynamic part consists of the analysis of API calls, in- and outgoing web requests and injected content scripts. Some calls to Chrome's extension API are considered malicious such as uninstalling other extensions or preventing the user to uninstall the extension itself. This is often accomplished by preventing the user to open Chrome's extension tab. Web requests are analyzed for modifications such as removing security relevant headers or changing the target server. To analyze the interaction with or manipulation of a web page Hulk uses so called \textit{honey pages}. Those are based on \textit{honeypots} which are special applications or server that appear to have weak security mechanisms to lure an attack that can then be analyzed. Honey pages consists of overridden DOM query functions that create elements on the fly. If a script queries for a DOM element the element will be created and any interaction will be monitored. \\
	
	\textit{WebEval} is an analysis tool to identify malicious chrome extensions \cite{190984}. Its main goal is to reduce the amount of human resources needed to verify that an extension is indeed malicious. Therefore it relies on an automatic analysis process whose results are valuated by an self learning algorithm. Ideally the system would run without human interaction. The research of Nav Jagpal \textit{et al}. shows that the false positive and false negative rates decreases over time but new threads result in a sharp increase. They arrived at the conclusion that human experts must always be a part of their system. In three years of usage WebEval analyzed 99,818 extensions in total and identified 9,523 (9.4\%) malicious extensions. Automatic detection identified 93.3\% of malicious extensions which were already known and 73,7\% of extensions flagged as malicious were confirmed by human experts. \\
	In addition to their analysis pipeline they stored every revision of an extension that was distributed to the Google Chrome web store in the time of their research. A weakly rescan targets extensions that fetch remote resources that may become malicious. New extensions are compared to stored extensions to identifying near duplicated extensions and known malicious code pattern. WebEval also targets the identification of developer who distribute malicious extensions and fake accounts inside the Google Chrome web store. Therefore reputation scans of the developer, the account's email address and login position are included in the analysis process.  \\
	The extension's behavior is dynamically analyzed with generic and manual created behavioral suits. Behavioral suits replay recorded interactions with a web page to trigger the extension's logic. Generic behavioral suits include techniques developed by Kapravelos	et al. for Hulk \cite{184485} such as \textit{honeypages}. Manual behavioral suits test an extension's logic explicit against known threads such as to uninstall another extension or modify CSP headers. In addition, they rely on anti virus software to detect malicious code and domain black lists to identify the fetching of possible harmful resources. If new threads surface WebEval can be expanded to quickly respond. New behavioral suits and detection rules for the self learning algorithm can target explicit threads. \\
	
	\textit{VEX} is a static analysis tool for Firefox Add-ons \cite{Bandhakavi:2011:VBE:1995376.1995398}. Sruthi Bandhakavi et al. analyzed the work flow of Mozilla's developers who manually analyze new Firefox Add-ons by searching for possible harmful code pattern. They implemented VEX to extend and automatize the developer's search and minimize the amount of false-positive results. VEX statically analyses the flow of information in the source code and creates a graph system that represents all possible information flows. They created pattern for the graph system that detect possible cross site scripting attacks with \textit{eval} or the DOM function \textit{innerHtml} and Firefox specific attacks that exploit the improper use of \textit{evalInSandbox} or wrapped JavaScript objects. More vulnerabilities can be covered by VEX by adding new flow pattern. VEX targets buggy Add-ons without harmful intent or code obfuscation. \\
	
	Oystein Hallaraker et al. developed an auditing system for Firefox's JavaScript engine to detect malicious code pieces \cite{Hallaraker:2005:DMJ:1078029.1078861}. The system logs all interaction JavaScript and the browser's functionalities such as the DOM or or the browser's native code. The auditing output is compared to pattern to identify possible malicious behavior. Hallaraker et al. did not propose any mechanism to verify that detection results are indeed malicious. The implemented pattern can also match benign code. Their work targets JavaScripts embedded into web pages. Applying their system to extensions could be difficult, because extensions do more often call the browser's functionalities in an benign way due to an extension's nature. \\
	
	
	
\section{Information Flow Control In JavaScript}
	
	Philipp Vogt et al. developed a system to secure the flow of sensitive data in JavaScript browsers and to prevent possible cross site scripting attacks \cite{ndss2007xss} . They taint data on creation and follow its flow by tainting the result of every statement such as simple assignments, arithmetical calculations, or control structures. For this purpose they modified the browser's JavaScript engine and also had to modify the browser's DOM implementation to prevent tainting loss if data is temporarily stored inside the DOM tree. The dynamic analysis only covers executed code. Code branches that indirect depend on sensitive data can not be examined. They added a static analysis to taint every variable inside the scope of tainted data to examine indirect dependencies. \\
	The system was designed to prevent possible cross site scripting attacks. If it recognizes the flow of sensitive data to an cross origin it prompts the user to confirm or decline the transfer. An empirical study on 1,033,000 unique web pages triggered 88,589 (8.58\%) alerts. But most alerts were caused by web statistics or user tracking services. This makes their system an efficient tool to control information flow to third parties. The system could be applied to extensions for the same purpose and as security mechanism to prevent data leaking in buggy extensions. \\
	
	\textit{Sabre} is a similar approach to the tainting system from Vogt et al. but focused on extensions \cite{Dhawan:2009:AIF:1723192.1723250, ndss2007xss}. It monitors the flow of sensitive information in JavaScript base browser extensions and detects modifications. The developers modified a JavaScript interpreter to add security labels to JavaScript objects. Sabre tracks these labels and rises an alert if information labeled as sensitive is accessed in an unsafe way. Although their system is focused on extensions it needs access to the whole browser and all corresponding JavaScript applications to follow the flow of data. This slows down the browser. Their own performance tests showed an overhead factor between 1.6 and 2.36. A further disadvantage is that the user has to decide if an alert is justified. The developer added a white list for false positive alarms to compensate this disadvantage. \\
